{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661a21e8-12f7-4af2-ae74-b15d6bdd2ded",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71242a35-5712-4913-8ca4-c8c25a97ac62",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01914de2-0e7b-4b01-bc59-89aab92955d0",
   "metadata": {},
   "source": [
    "After learning about Adversarial Search in Artificial Intelligence and Game Theory, I wanted to dive deeper into its use in modern machine learning. That's when I discovered Generative Adversarial Networks (GANs).\n",
    "\n",
    "A GAN is a type of generative model that has two main parts: a Generative model (G) and a Discriminative model (D). These components interact with each other in a way that resembles a minimax game. The Discriminative model aims to maximize its value function, while the Generative model aims to minimize its value function.\n",
    "\n",
    "The goal of this project is to train a generative model which can produce images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be8579-f2ef-40a1-8ab9-7e1338e60ce1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3cd1b-7233-48ae-bd22-98faa4a259ec",
   "metadata": {},
   "source": [
    "$z$ : noise \n",
    "\n",
    "$x$ : input of discriminator\n",
    "\n",
    "$G$ : generator function, $\\theta_g$ : parameters of function G\n",
    "\n",
    "$D$ : discriminator function, $\\theta_d$ : parameters of function D\n",
    "\n",
    "$P_z$ : noise distribution\n",
    "\n",
    "$P_{data}$ : real data distribution\n",
    " \n",
    "$P_g$ : generated data using G distribution\n",
    "\n",
    "$m$ : mini batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac64db-6ac3-4425-b926-93bcb054949e",
   "metadata": {},
   "source": [
    "## Overview of GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedc50c-6d2c-40c4-b7f3-cbd17009101f",
   "metadata": {},
   "source": [
    "As i mentioned earlier, the GAN consists of two parts. The generative model takes noisy variables $Z$ as input and maps them to the data space. This mapping can be represented by a differentiable function $G(z;\\theta_g) = x$, which can be implemented as a multilayer perceptron with parameters ùúÉùëî. On the other hand, the discriminative model's task is to determine whether inputs belong to the data distribution or not. It operates like a classifier, labeling inputs based on their likelihood of coming from the data distribution. The function $D(x; \\theta_d)$ represents the probability of $X$ belonging to the data distribution.\n",
    "\n",
    "Now, we can combine these two components. The generator's objective is to map random noisy inputs $Z$ to $X$ in such a way that the discriminator cannot detect that they are generated samples from $P_g$. At the same time, the discriminator aims to learn the most accurate model possible, enabling it to distinguish between real and fake data.\n",
    "\n",
    "After training this model, we will be able to generate data (such as images) that closely resemble real data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c2b2b-577f-477a-b436-3af347fcc4c8",
   "metadata": {},
   "source": [
    "## Generator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5370a5-8e34-4ab1-9732-6c9afc49c722",
   "metadata": {},
   "source": [
    "What the generator does is similar to finding a transformation function that minimizes an objective function. In mathematical terms, let's assume that $Z$ is drawn from a distribution called $P_z$. Our goal is to find a transformation function, denoted as $G$, that can accurately estimate the real data distribution called $P_{data}$. Essentially, the generator's objective is to make the discriminator unable to distinguish between real data from $P_{data}$ and fake data from $P_g$.\n",
    "\n",
    "To achieve this, we can define a suitable loss function for the generator using binary cross entropy.\n",
    "\n",
    "$loss_G = -\\frac{1}{m}\\sum_{z} \\log(1 - D(G(z)))$ \n",
    "\n",
    "\n",
    "**Note : Generative loss doesn't have term $\\log(D(x))$ because when we calculate gradient of loss with respect to $\\theta_g$, $\\frac{\\partial D}{\\partial \\theta_g}$ is equal to zero.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce792b5-17b7-436b-944c-b77314481719",
   "metadata": {},
   "source": [
    "## Discriminator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef6ce0-c6f8-4f4f-bdfb-0e62e4484b62",
   "metadata": {},
   "source": [
    "The discriminator is responsible for labeling the inputs by determining if they belong to the data distribution. In simpler terms, the discriminator acts like a sigmoid function that outputs the probability of an input $x$ belonging to the real data distribution $P_{data}$. It is reasonable to use binary cross entropy as the loss function for the discriminator. Therefore one possible loss function for the discriminator might be binary cross entropy. \n",
    "\n",
    "$loss_D = -\\frac{1}{m}\\sum y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y}) = -\\frac{1}{m}\\sum_{x,z} \\log(D(x)) + \\log(1-D(G(z)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c5532-c96b-4216-8285-16a764676366",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244cbea-3240-464e-bf8a-bbd2ff8f6da9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "893ddf98-b0f8-4945-9fa8-9b638caff984",
   "metadata": {},
   "source": [
    "## Theoretical Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf847a-5ff0-4e9f-b0b3-160367587f0b",
   "metadata": {},
   "source": [
    "In this part, let's dive into the math behind GANs.\n",
    "\n",
    "To begin, we introduce a new loss function that leverages the adversarial nature of the network. In previous sections, the loss functions we defined were based on practical usage. However, the authors of GANs determined a value function using a minimax game, which can be expressed as follows:\n",
    "\n",
    "$V(D,G) = E_{x \\sim P_{data}}[\\log(D(x))] + E_{z \\sim P_{z}}[log(1-D(G(z)))]$\n",
    "\n",
    "So, if we consider D as a maximum node and G as a minimum node, we can view the network as an optimization problem:\n",
    "\n",
    "$min_G max_D V(D,G) = E_{x \\sim P_{data}}[\\log(D(x))] + E_{z \\sim P_{z}}[log(1-D(G(z)))]$\n",
    "\n",
    "This equation effectively demonstrates the competition. It is consistent with our previous definition of loss functions. Although those loss functions were separate, decreasing the loss of G will result in an increase in the loss of D, and vice versa. Summation over all xs and zs and dividing by m can be seen as an expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ebc904-d189-46ac-a92c-60305091f62b",
   "metadata": {},
   "source": [
    "### Global Optimality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcfb952-a0f2-47f0-a8b0-013e9731eb31",
   "metadata": {},
   "source": [
    "For this part we are going to show two things : \n",
    "    \n",
    "1.What is the optimal D for a fixed G.\n",
    "\n",
    "2.The global minimum is achieved if and only if $p_g = p_{data}$.\n",
    "\n",
    "Lets show the first one.\n",
    "\n",
    "If G is fixed, then we only need to maximize value function based on D.\n",
    "\n",
    "<ul>\n",
    "\n",
    "Value function = $E_{x \\sim P_{data}}[\\log(D(x))] + E_{z \\sim P_{z}}[log(1-D(G(z)))]$ (1)\n",
    "\n",
    "$E[f(X)] = \\int_{x} p(x) f(x) dx$ (2)\n",
    "\n",
    "$^{(1),(2)}=> V(G,D) = \\int_{x} p_{data}(x) log(D(x)) dx + \\int_{z}p_z(z) log(1-D(G(z))) dz$.\n",
    "\n",
    "$G(z)= x$ and $P_g$ and $P_{data}$ come from same domain $=> V(G,D) = \\int_{x} p_{data}(x) log(D(x)) + p_{g}(x) log(1-D(x)) dx$\n",
    "\n",
    "Now we differentiate from above equation in order to find optimal D :\n",
    "\n",
    "$\\frac{\\partial V(G,D)}{\\partial D} =^{(*)} \\int_{x} \\frac{1}{\\partial D} (p_{data}(x) log(D(x)) + p_{g}(x) log(1-D(x))) dx = \\int_{x} \\frac{p_{data}(x)}{D(x)} - \\frac{p_{g}(x)}{1-D(x)} dx =>$\n",
    "\n",
    "$\\int_{x} \\frac{p_{data}(x)}{D(x)} dx = \\int_{x} \\frac{p_{g}(x)}{1-D(x)} dx =^{(**)} \\frac{p_{data}(x)}{D(x)} = \\frac{p_{g}(x)}{1-D(x)} =>$\n",
    "\n",
    "$D^*(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_{g}(x)}$\n",
    "</ul>\n",
    "\n",
    "\\* : I used **differentiation under the integral sign rule**. Note that we are calculating integrals over finite intervals.\n",
    "\n",
    "\\** : $\\int_{a}^{x} f(x) dx = \\int_{a}^{x} g(x) dx =>^{\\frac{1}{\\partial x}} f(x) = g(x)$, so for any x, f is equal to g.\n",
    "\n",
    "\n",
    "Now we substitute D* with D in value function equation. We will use new function $C(G)$ and with using this function we are able to minimize $max V$ based on G.\n",
    "\n",
    "<ul>\n",
    "\n",
    "$C(G) = max_D V(G,D) = E_{x \\sim P_{data}}[\\log(\\frac{p_{data}(x)}{p_{data}(x) + p_{g}(x)})] + E_{x \\sim P_{g}}[log(\\frac{p_{g}(x)}{p_{data}(x) + p_{g}(x)})]$\n",
    "    \n",
    "</ul>\n",
    "\n",
    "We have to prove : The global minimum of the $C(G)$ is achieved if and only if $p_g=p_{data}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10532aa9-5671-47c5-b06b-a64e27b3dbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
